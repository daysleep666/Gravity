---
layout: post
title:  "redis常见问题"
date:   2019-8-1 22:00:00
categories: golang
---

## 缓存失效

    一. 缓存穿透
        
        在redis中访问一个key发现它不存在,就会继续访问数据库,这时候redis就起不到缓存的作用了.通过不存在的key恶意攻击.

        1.解决方案
            1.1 缓存不存在的key,值设为零值
            1.2 套一个布隆过滤器.
                一个key经过hash后落到一个int64的某一二进制位上,如果二进制为1则存在,反之不存在.
                
![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/布隆.png)

    二. 缓存雪崩

        所有的key在同一时间失效,导致数据库访问量瞬间增大.

        1. 解决方案
            1.1 key设置random的过期时间.不同一时间失效就好.

## 一致性哈希

    根据哈希结果来决定应该访问哪个节点

    1. 先看下根据普通哈希算法分配流量

        hash(ip) % 节点数量

        无论增加还是减少节点数量,都会导致大部分key失效

    2. 一致性哈希算法
        将节点ip映射(hash)到一个环上,key也映射(hash)到这个环上某一点,然后顺时针找到最近的那个节点.
        
![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/hash1.png)

        2.1 增加节点只会影响部分key的映射.

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/hash2.png)

        2.2 减少节点只会影响部分key的映射.

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/hash3.png)

## 共识算法

    这个算法源于拜占庭将军问题

    有一个元帅和四个将军,平常都是元帅发布命令,将军去做的

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/raft1.png)

    突然有一天元帅吃寒汉堡噎死了

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/raft2.png)

    四个将军中有个判断,他趁元帅死了,开始发布错误的命令坑队友.

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/raft3.png)

    这就是一个简单的拜占庭将军问题.

    为了解决这个问题就需要一个共识算法.

    以raft算法举例.

    在失去leader之后,每个节点都会启动一个随机定时器,定时器到头之后的那个节点成为candidate.
    candidate给其他节点发请求,要求他们给自己投票,让自己当leader.

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/raft4.png)

    当超过半数节点同意自己后,从candidate升为leader

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/raft5.png)

## 功能点

### 架构

    redis是单线程架构

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/r1.png)

    所有的命令都会进入一个命令队列串行执行

    速度快的理由:

        1. 在内存中
        2. 多路io复用
                你是一个富豪,你有一个专门的厨师为你做饭
            2.1 阻塞io
                你饿了,要求厨师给你做饭,然后就坐到饭桌前直到饭做好了为止.

            2.2 非阻塞io
                你又饿了,要求厨师给你做饭,但是你这回躺在了床上每过一段时间就去问下厨师有没有做好饭.

            2.3 多路复用io
                你破产了,你跟别人共用一个厨师,你需要等厨师做完上一个人的菜才能为你做菜.

![avatar](https://raw.githubusercontent.com/daysleep666/blog/master/src/img/article/redis/r2.png)

        3. 单线程
           3.1 不需要线程切换.没有性能损耗
           3.2 不存在并发,不需要加锁

### 过期策略

    1. 定期删除

       每隔一段时间,随机检查n个key,如果过期了,就干掉它.

    2. 惰性删除

       每当访问一个key的时候,检查它是否过期,过期就删除

    3. LRU  [这个跟过期没关系了,主要是内存如果满了,怎么办]
    
       如果内存空间满了,默认删除最近最少使用的key.

### redis和数据库双写一致

    在更新数据库和更新redis时可能会出现不一致产生脏数据.

    解决方案:
        
        1. 设置过期时间.

        2. 如果不能设置过期时间,可以采取延后删除缓存的策略.

            举个例子
            线程a删除缓存
            线程b读取缓存,读不到
            线程b读取数据库,读取了旧的值
            线程b将旧值写入缓存
            线程a修改数据库为新值.

            在线程a删除缓存和修改数据库间出现了不一致,导致线程b写入了脏值.所以在线程a修改完数据库后需要删除缓存.

### redis为什么不推荐做为数据库使用

    1. 备份

        1.1 rdb 全备份,当前数据的快照

            每隔一定时间备份一次,如果在两次备份间挂掉,那期间的数据都丢了

        1.2 aof 写命令追加日志

            1.2.1 实时写,每有一个写操作就要写下磁盘,会严重影响redis的性能.redis之所以快就是因为纯内存操作,一般没有磁盘io,

            1.2.2 攒一段时间一起写,容易丢失数据.

    2. redis启动的时候会将全部数据加载到内存.如果数据量非常大,启动会很慢,也会很占内存.

### 性能测试

    1. docker exec -ti redis-6379 redis-benchmark -h 127.0.0.1 -p 6379 -q -c 100 -n 100000

    -c	指定并发连接数	
    -n	指定请求数
    -q	强制退出 redis。仅显示 query/sec 值
    -d	以字节的形式指定 SET/GET 值的数据大小  默认2

```
PING_INLINE: 115340.26 requests per second
PING_BULK: 122399.02 requests per second
SET: 122850.12 requests per second
GET: 123152.71 requests per second
INCR: 122699.39 requests per second
LPUSH: 123001.23 requests per second
RPUSH: 123304.56 requests per second
LPOP: 121654.50 requests per secondmemtier
RPOP: 122399.02 requests per second
SADD: 122699.39 requests per second
HSET: 123152.71 requests per second
SPOP: 123152.71 requests per second
LPUSH (needed to benchmark LRANGE): 121506.68 requests per second
LRANGE_100 (first 100 elements): 60790.27 requests per second
LRANGE_300 (first 300 elements): 26357.41 requests per second
LRANGE_500 (first 450 elements): 18152.12 requests per second
LRANGE_600 (first 600 elements): 15227.65 requests per second
MSET (10 keys): 117233.30 requests per second
```

    2. docker exec -ti redis-6379 redis-benchmark -h 127.0.0.1 -p 6379 -d 100 -q -c 50 -n 100000 

    跟2字节大小的key结果差不多.

    3. docker exec -ti redis-6379 redis-benchmark -h 127.0.0.1 -p 6379 -d 1000 -q -c 50 -n 100000 


```
除lrange操作外,其他操作每秒执行数没太大改变

key的字节数乘以500

LRANGE_100 (first 100 elements): 16265.45 requests per second  是之前的1/3
LRANGE_300 (first 300 elements): 4922.71 requests per second    是之前的1/5
LRANGE_500 (first 450 elements): 2971.06 requests per second    是之前的1/6
LRANGE_600 (first 600 elements): 2186.89 requests per second    是之前的1/8
```


    3. docker exec -ti redis-6379 redis-benchmark -h 127.0.0.1 -p 6379 -d 100000 -q -c 50 -n 100000

```
SET: 20772.75 requests per second
GET: 24402.15 requests per second

lpush操作直接导致redis-server崩溃

```


    4. 测试结果
```
单机redis

每秒读写数是12万左右

key的字节大小不会影响插入查询性能.(不考虑内存方面)
但是会严重影响range性能.经测试,key的字节大小超过100字节就会降低range性能.

redis-client一定要是keep-alive的

之前的测试都是单一值,随机key会让redis的get,set下降1/4

```